{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd1d4f1",
   "metadata": {},
   "source": [
    "# What can I tell about start and end tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ddd94d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stefan.Beuchert\\Desktop\\backup_from_kubectl\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba11f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "number_of_features = 10 # the default value\n",
    "number_of_samples = 5000 # the default value\n",
    "\n",
    "source_path_for_data = f'data/Data_Preparation/lime_ns_{number_of_samples}_nf_{number_of_features}_after_frequency_analysis.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7742996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.get_data import enhance_data_with_question_type\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb7d362",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4bbc462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>context</th>\n",
       "      <th>document_id</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>usage</th>\n",
       "      <th>prediction</th>\n",
       "      <th>explanation</th>\n",
       "      <th>question_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37495</th>\n",
       "      <td>Wie viele Amerikaner fühlen sich mehr als eine...</td>\n",
       "      <td>[{'answer_id': 37854, 'document_id': 41057, 'q...</td>\n",
       "      <td>Race__United_States_Census_\\n\\n=== „Race“ ===\\...</td>\n",
       "      <td>41057</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>fast sieben Millionen</td>\n",
       "      <td>{'position_id': {'0': 0, '1': 1, '2': 2, '3': ...</td>\n",
       "      <td>wie viel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36553</th>\n",
       "      <td>Wer wanderte nach North Carolina Anfang des 20...</td>\n",
       "      <td>[{'answer_id': 36895, 'document_id': 40789, 'q...</td>\n",
       "      <td>North_Carolina\\n\\n==== Europäische Amerikaner ...</td>\n",
       "      <td>40789</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>eine Gruppe orthodoxer Einwanderer aus der Ukr...</td>\n",
       "      <td>{'position_id': {'0': 0, '1': 1, '2': 2, '3': ...</td>\n",
       "      <td>wer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36597</th>\n",
       "      <td>Was gehört zum Stadtkirchenverband Hannover?</td>\n",
       "      <td>[{'answer_id': 36938, 'document_id': 40797, 'q...</td>\n",
       "      <td>Hannover\\n\\n==== Evangelisch-lutherische Kirch...</td>\n",
       "      <td>40797</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>Alle landeskirchlichen evangelischen Kirchenge...</td>\n",
       "      <td>{'position_id': {'0': 0, '1': 1, '2': 2, '3': ...</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37392</th>\n",
       "      <td>Wann starb Athanasius der Große?</td>\n",
       "      <td>[{'answer_id': 37749, 'document_id': 41075, 'q...</td>\n",
       "      <td>Athanasius_der_Große\\nGriechische Ikone, Titul...</td>\n",
       "      <td>41075</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>2. Mai 373</td>\n",
       "      <td>{'position_id': {'0': 0, '1': 1, '2': 2, '3': ...</td>\n",
       "      <td>wann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37351</th>\n",
       "      <td>Welche Länder liegen östlich des Irans?</td>\n",
       "      <td>[{'answer_id': 37706, 'document_id': 41082, 'q...</td>\n",
       "      <td>Iran\\n\\n=== Antike und Mittelalter ===\\nDas he...</td>\n",
       "      <td>41082</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>Indien und China</td>\n",
       "      <td>{'position_id': {'0': 0, '1': 1, '2': 2, '3': ...</td>\n",
       "      <td>welche</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "37495  Wie viele Amerikaner fühlen sich mehr als eine...   \n",
       "36553  Wer wanderte nach North Carolina Anfang des 20...   \n",
       "36597       Was gehört zum Stadtkirchenverband Hannover?   \n",
       "37392                   Wann starb Athanasius der Große?   \n",
       "37351            Welche Länder liegen östlich des Irans?   \n",
       "\n",
       "                                                 answers  \\\n",
       "37495  [{'answer_id': 37854, 'document_id': 41057, 'q...   \n",
       "36553  [{'answer_id': 36895, 'document_id': 40789, 'q...   \n",
       "36597  [{'answer_id': 36938, 'document_id': 40797, 'q...   \n",
       "37392  [{'answer_id': 37749, 'document_id': 41075, 'q...   \n",
       "37351  [{'answer_id': 37706, 'document_id': 41082, 'q...   \n",
       "\n",
       "                                                 context  document_id  \\\n",
       "37495  Race__United_States_Census_\\n\\n=== „Race“ ===\\...        41057   \n",
       "36553  North_Carolina\\n\\n==== Europäische Amerikaner ...        40789   \n",
       "36597  Hannover\\n\\n==== Evangelisch-lutherische Kirch...        40797   \n",
       "37392  Athanasius_der_Große\\nGriechische Ikone, Titul...        41075   \n",
       "37351  Iran\\n\\n=== Antike und Mittelalter ===\\nDas he...        41082   \n",
       "\n",
       "       is_impossible usage                                         prediction  \\\n",
       "37495          False  test                              fast sieben Millionen   \n",
       "36553          False  test  eine Gruppe orthodoxer Einwanderer aus der Ukr...   \n",
       "36597          False  test  Alle landeskirchlichen evangelischen Kirchenge...   \n",
       "37392          False  test                                         2. Mai 373   \n",
       "37351          False  test                                   Indien und China   \n",
       "\n",
       "                                             explanation question_type  \n",
       "37495  {'position_id': {'0': 0, '1': 1, '2': 2, '3': ...      wie viel  \n",
       "36553  {'position_id': {'0': 0, '1': 1, '2': 2, '3': ...           wer  \n",
       "36597  {'position_id': {'0': 0, '1': 1, '2': 2, '3': ...           was  \n",
       "37392  {'position_id': {'0': 0, '1': 1, '2': 2, '3': ...          wann  \n",
       "37351  {'position_id': {'0': 0, '1': 1, '2': 2, '3': ...        welche  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "data_df = pd.read_json(source_path_for_data)\n",
    "# data_df['explanation'] = [pd.DataFrame(exp) for exp in data_df['explanation'].tolist()]\n",
    "data_df = enhance_data_with_question_type(data_df)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b3328",
   "metadata": {},
   "source": [
    "## Extract start and end tokens as well as the corresponding POS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c72a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction tokens\n",
    "prediction_list = data_df['prediction'].tolist()\n",
    "prediction_list_split = [p.split() for p in prediction_list]\n",
    "\n",
    "prediction_list_split_nan = []\n",
    "for p in prediction_list_split:\n",
    "    if len(p) == 0:\n",
    "        prediction_list_split_nan.append([None])\n",
    "    else:\n",
    "        prediction_list_split_nan.append(p)\n",
    "\n",
    "# get prediction pos\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "pos_prediction_list = []\n",
    "\n",
    "for p in prediction_list_split_nan:\n",
    "    if p[0] is not None:\n",
    "        nlp_tags = nlp(' '.join(p))\n",
    "        list_pos_tags = [i.pos_ for i in nlp_tags]\n",
    "        \n",
    "        pos_prediction_list.append(list_pos_tags)\n",
    "        \n",
    "    else:\n",
    "        pos_prediction_list.append(p)\n",
    "\n",
    "data_df['start_token'] = [p[0] for p in prediction_list_split_nan]\n",
    "data_df['end_token'] = [p[-1] for p in prediction_list_split_nan]\n",
    "\n",
    "data_df['start_token_pos'] = [p[0] for p in pos_prediction_list]\n",
    "data_df['end_token_pos'] = [p[-1] for p in pos_prediction_list]\n",
    "\n",
    "data_df['start_token'].fillna(value=np.nan, inplace=True)\n",
    "data_df['end_token'].fillna(value=np.nan, inplace=True)\n",
    "data_df['start_token_pos'].fillna(value=np.nan, inplace=True)\n",
    "data_df['end_token_pos'].fillna(value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c0ab4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37495          fast\n",
       "36553          eine\n",
       "36597          Alle\n",
       "37392            2.\n",
       "37351        Indien\n",
       "            ...    \n",
       "41111           Nur\n",
       "38148       Cassava\n",
       "37012            Im\n",
       "38199    Allerdings\n",
       "38841           NaN\n",
       "Name: start_token, Length: 2176, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['start_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6dc1c",
   "metadata": {},
   "source": [
    "## Get insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43f732f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df[data_df['start_token'].notna()]['start_token'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00093040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df['end_token'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13c4e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df['start_token_pos'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a116e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_df['end_token_pos'].value_counts()#.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f184a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN     703\n",
      "PROPN    624\n",
      "NUM      259\n",
      "PUNCT    220\n",
      "VERB     114\n",
      "AUX       58\n",
      "X         34\n",
      "ADV       31\n",
      "ADJ       11\n",
      "ADP        2\n",
      "PRON       2\n",
      "DET        1\n",
      "PART       1\n",
      "CCONJ      1\n",
      "Name: end_token_pos, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a5fd6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34ed41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d16c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADP      378\n",
       "DET      360\n",
       "NOUN     285\n",
       "PROPN    249\n",
       "NUM      216\n",
       "ADV      174\n",
       "X        165\n",
       "ADJ       82\n",
       "SCONJ     46\n",
       "PUNCT     41\n",
       "PRON      32\n",
       "VERB      21\n",
       "CCONJ      5\n",
       "AUX        5\n",
       "PART       2\n",
       "Name: start_token_pos, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['start_token_pos'].value_counts()#.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d8252f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b708dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create am function for my explainer object that takes data_df (for each quesiton type) \n",
    "# and returns the top pos tokens for start and end with probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e77c9b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_preferences_for_start_and_end_tokens(data_df):\n",
    "    \n",
    "    # get prediction tokens\n",
    "    prediction_list = data_df['prediction'].tolist()\n",
    "    prediction_list_split = [p.split() for p in prediction_list]\n",
    "\n",
    "    prediction_list_split_nan = []\n",
    "    for p in prediction_list_split:\n",
    "        if len(p) == 0:\n",
    "            prediction_list_split_nan.append([None])\n",
    "        else:\n",
    "            prediction_list_split_nan.append(p)\n",
    "\n",
    "    # get prediction pos\n",
    "    nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "    pos_prediction_list = []\n",
    "\n",
    "    for p in prediction_list_split_nan:\n",
    "        if p[0] is not None:\n",
    "            nlp_tags = nlp(' '.join(p))\n",
    "            list_pos_tags = [i.pos_ for i in nlp_tags]\n",
    "\n",
    "            pos_prediction_list.append(list_pos_tags)\n",
    "\n",
    "        else:\n",
    "            pos_prediction_list.append(p)\n",
    "\n",
    "    data_df['start_token'] = [p[0] for p in prediction_list_split_nan]\n",
    "    data_df['end_token'] = [p[-1] for p in prediction_list_split_nan]\n",
    "\n",
    "    data_df['start_token_pos'] = [p[0] for p in pos_prediction_list]\n",
    "    data_df['end_token_pos'] = [p[-1] for p in pos_prediction_list]\n",
    "\n",
    "    data_df['start_token'].fillna(value=np.nan, inplace=True)\n",
    "    data_df['end_token'].fillna(value=np.nan, inplace=True)\n",
    "    data_df['start_token_pos'].fillna(value=np.nan, inplace=True)\n",
    "    data_df['end_token_pos'].fillna(value=np.nan, inplace=True)\n",
    "    \n",
    "    start_token_pos_df = data_df['start_token_pos'].value_counts().to_frame()\n",
    "    start_token_pos_df['percent'] = (start_token_pos_df['start_token_pos'] / start_token_pos_df['start_token_pos'].sum()) *100\n",
    "    \n",
    "    end_token_pos_df = data_df['end_token_pos'].value_counts().to_frame()\n",
    "    end_token_pos_df['percent'] = (end_token_pos_df['end_token_pos'] / end_token_pos_df['end_token_pos'].sum()) *100\n",
    "    \n",
    "    start_token_pos_df = start_token_pos_df.sort_values(by=['percent'], ascending=False)\n",
    "    end_token_pos_df = end_token_pos_df.sort_values(by=['percent'], ascending=False)\n",
    "    \n",
    "    print(start_token_pos_df)\n",
    "    print(end_token_pos_df)\n",
    "    \n",
    "    res = {\n",
    "        'top_pos_for_start_token' : start_token_pos_df.index[0],\n",
    "        'second_top_pos_for_start_token' : start_token_pos_df.iloc[0]['percent'],\n",
    "        \n",
    "        'top_pos_for_start_token_probability' : start_token_pos_df.index[1],\n",
    "        'second_top_pos_for_start_token_probability' : start_token_pos_df.iloc[1]['percent'],\n",
    "        \n",
    "        \n",
    "        'top_pos_for_end_token' : end_token_pos_df.index[0],\n",
    "        'top_pos_for_end_token_probability' : end_token_pos_df.iloc[0]['percent'],\n",
    "        \n",
    "        'secondtop_pos_for_end_token' : end_token_pos_df.index[1],\n",
    "        'second_top_pos_for_end_token_probability' : end_token_pos_df.iloc[1]['percent'],\n",
    "    }\n",
    "    \n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9356fcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       start_token_pos    percent\n",
      "PROPN               19  20.430108\n",
      "DET                 14  15.053763\n",
      "ADP                 13  13.978495\n",
      "NOUN                11  11.827957\n",
      "ADV                 10  10.752688\n",
      "X                    7   7.526882\n",
      "NUM                  7   7.526882\n",
      "ADJ                  3   3.225806\n",
      "PUNCT                3   3.225806\n",
      "SCONJ                2   2.150538\n",
      "VERB                 2   2.150538\n",
      "CCONJ                1   1.075269\n",
      "PRON                 1   1.075269\n",
      "       end_token_pos    percent\n",
      "NOUN              35  37.634409\n",
      "PROPN             32  34.408602\n",
      "NUM                8   8.602151\n",
      "VERB               5   5.376344\n",
      "ADV                4   4.301075\n",
      "PUNCT              3   3.225806\n",
      "AUX                3   3.225806\n",
      "X                  2   2.150538\n",
      "ADP                1   1.075269\n",
      "{'top_pos_for_start_token': 'PROPN', 'second_top_pos_for_start_token': 20.43010752688172, 'top_pos_for_start_token_probability': 'DET', 'second_top_pos_for_start_token_probability': 15.053763440860216, 'top_pos_for_end_token': 'NOUN', 'top_pos_for_end_token_probability': 37.634408602150536, 'secondtop_pos_for_end_token': 'PROPN', 'second_top_pos_for_end_token_probability': 34.40860215053764}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stefan.Beuchert\\AppData\\Local\\Temp\\ipykernel_12100\\87224739.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['start_token'] = [p[0] for p in prediction_list_split_nan]\n",
      "C:\\Users\\Stefan.Beuchert\\AppData\\Local\\Temp\\ipykernel_12100\\87224739.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['end_token'] = [p[-1] for p in prediction_list_split_nan]\n",
      "C:\\Users\\Stefan.Beuchert\\AppData\\Local\\Temp\\ipykernel_12100\\87224739.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['start_token_pos'] = [p[0] for p in pos_prediction_list]\n",
      "C:\\Users\\Stefan.Beuchert\\AppData\\Local\\Temp\\ipykernel_12100\\87224739.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['end_token_pos'] = [p[-1] for p in pos_prediction_list]\n",
      "C:\\Users\\Stefan.Beuchert\\AppData\\Local\\Temp\\ipykernel_12100\\87224739.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['start_token'].fillna(value=np.nan, inplace=True)\n",
      "C:\\Users\\Stefan.Beuchert\\AppData\\Local\\Temp\\ipykernel_12100\\87224739.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['end_token'].fillna(value=np.nan, inplace=True)\n",
      "C:\\Users\\Stefan.Beuchert\\AppData\\Local\\Temp\\ipykernel_12100\\87224739.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['start_token_pos'].fillna(value=np.nan, inplace=True)\n",
      "C:\\Users\\Stefan.Beuchert\\AppData\\Local\\Temp\\ipykernel_12100\\87224739.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_df['end_token_pos'].fillna(value=np.nan, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'top_pos_for_start_token': 'PROPN',\n",
       " 'second_top_pos_for_start_token': 20.43010752688172,\n",
       " 'top_pos_for_start_token_probability': 'DET',\n",
       " 'second_top_pos_for_start_token_probability': 15.053763440860216,\n",
       " 'top_pos_for_end_token': 'NOUN',\n",
       " 'top_pos_for_end_token_probability': 37.634408602150536,\n",
       " 'secondtop_pos_for_end_token': 'PROPN',\n",
       " 'second_top_pos_for_end_token_probability': 34.40860215053764}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pos_preferences_for_start_and_end_tokens(data_df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c044d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
